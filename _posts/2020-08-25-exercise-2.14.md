---
layout:      post
title:       "Exercise 2.14"
sorting_tag: "214"
tags:        [chapter 2, layered cake, symmetrisation, Chernoff bound, incomplete]
comments:    true
date:        2020-08-25
---

## (a)

By the layered cake trick
\begin{align}
  \V (X)
  =
  \int_0^\infty
    \P ((X - \mu)^2 > t)
    \, \sd t
  \leq
  c_1
  \int_0^\infty
    e^{- c_2 t}
    \, \sd t
  =
  \frac{c_1}{c_2}
  \, .
\end{align}


## (b)

Take $$ X $$ to be a Rademacher random variable. Then any $$ m_X \in [-1 , 1] $$
is a median.


## (c)

We will proceed by proving the bound for the case of (i) large
$$ t \geq \alpha \Delta $$, and (ii) small $$ t < \alpha \Delta $$, where
$$ \Delta = | \E [X] - m_X |$$, and
$$ \alpha > 0 $$ is an auxiliary parameter which we will choose later.

__(i) $$ t \geq \alpha \Delta $$:__
Using $$ | X - m_X | \leq \Delta + | X - E [X] | $$
\begin{align}
  \P (|X - m_X| \geq t)
  &=
  \P \left(|X - m_X| \geq \tfrac{t}{\alpha} + (1 - \tfrac{1}{\alpha})t\right)
  \newline
  &\leq
  \P \left( | X - m_X | \geq \Delta + (1 - \tfrac{1}{\alpha}) t \right)
  \newline
  &\leq
  \P \left( | X - \E [X] | \geq (1 - \tfrac{1}{\alpha}) t \right)
  \leq
  c_1 e^{-c_2 (1 - \alpha^{-1})^2 t^2}
  \, .
\end{align}

__(ii) $$ t < \alpha \Delta $$:__ Noticing the bound from (i) grows
as $$ t \downarrow 0 $$, the strategy we take is to inflate said bound
sufficiently so that it holds vacuously for all $$ 0 \leq t < \alpha \Delta $$.
Introducing another auxiliary parameter $$ \beta \geq 1 $$, we therefore require
\begin{align}
  \beta c_1 e^{-c_2 (1 - \alpha^{-1})^2 t^2}
  \>
  \beta c_1 e^{-c_2 (\alpha - 1)^2 \Delta^2}
  \geq
  1
  \geq
  \P (|X - m_X| \geq t)
  \, .
\end{align}
The crucial observation here is that the assumed bounds
\begin{align}
  \P (X \geq \E [X] + t) &\leq c_1 e^{- c_2 t^2 } \, , \newline
  \P (X \leq \E [X] - t) &\leq c_1 e^{- c_2 t^2 } \, ,
\end{align}
imply that for either $$ \E [X] + t $$ or $$ \E [X] - t $$ to be a median
(i.e., satisfy $$ \P (X \geq m_X) \geq \tfrac{1}{2} $$ and
$$ \P (X \leq m_X) \geq \tfrac{1}{2} $$ respectively),
we must have $$ c_1 e^{- c_2 t^2 } \geq \frac{1}{2} $$.
Hence
\begin{align}
  m_X
  \in
  \left[
    \E[X] - \sqrt{\tfrac{1}{c_2}\log(2 c_1)} ,
    \E[X] + \sqrt{\tfrac{1}{c_2}\log(2 c_1)}
  \right]
  \, ,
\end{align}
which provides a bound for $$ \Delta $$.
Substituting into the above expression
\begin{align}
  \beta c_1 e^{- c_2 (\alpha - 1)^2 \Delta^2}
  \geq
  \beta c_1 e^{- (\alpha - 1)^2 \log 2 c_1}
  =
  \beta c_1 \left( \tfrac{1}{2 c_1} \right)^{(\alpha - 1)^2}
  \geq
  1
  \, .
\end{align}
Since we have no control over $$ c_1 $$, we must set
$$ \alpha = 2 $$ ($$ \alpha = 0 $$ is inadmissable because we have divided by
$$ \alpha $$ above). This then also necessitates setting $$ \beta = 2 $$.

Putting (i) and (ii) together
\begin{align}
  \P (|X - m_X| \geq t)
  \leq
  c_3
  e^{- c_4 t^2}
  \, ,
\end{align}
for $$ c_3 = 2 c_1 $$ and $$ c_4 = \tfrac{c_2}{4} $$ which improves upon
each of the required constants by a factor of two.


## (d)

Applying the Chernoff bound, for any $$ \lambda > 0 $$
\begin{align}
  \P ( | X - \E [X] | \geq t )
  =
  \P \bigl( e^{\lambda (X - \E [X])^2} \geq e^{\lambda t^2} \bigr)
  \leq
  e^{- \lambda t^2}
  \E \bigl[e^{\lambda (X - \E [X])^2}\bigr]
  \, .
\end{align}
Since we are trying to establish $$ X - \E [X] $$ behaves like a sub-Gaussian
random variable, and Theorem 2.6(IV) tells us
$$ \E [ e^{\lambda (X - \E[X])^2} ] < \infty $$ for such random variables,
our goal will be to obtain a similar bound here.

Our approach is based on symmetrisation. Introducing $$ Y $$ as an independent
copy of $$ X $$, we can use the convexity of $$ x \mapsto e^{\lambda x^2} $$
and the Jensen's inequality to obtain the symmetrised
\begin{align}
  \E_X \bigl[e^{\lambda (X - \E_Y [Y])^2}\bigr]
  \leq
  \E_{X, Y} \bigl[e^{\lambda (X - Y)^2}\bigr]
  \, .
\end{align}
The right-hand side can be bounded using the layered cake trick
\begin{align}
  \E \bigl[ e^{\lambda (X - Y)^2} \bigr]
  &=
  \int\_0^\infty
    \P \bigl( e^{\lambda (X - Y)^2} \geq u \bigr) \, \sd u
  \newline
  &\overset{\text{(i)}}{\leq}
  \alpha
  +
  \int\_{\alpha}^\infty
    \P \bigl( e^{\lambda (X - Y)^2} \geq u \bigr) \, \sd u
  \newline
  &\overset{\text{(ii)}}{=}
  \alpha
  +
  \lambda
  \int\_{\frac{\log \alpha}{\lambda}}^\infty
    e^{\lambda v}
    \P (|X - Y| \geq \sqrt{v})
    \, \sd v
  \, ,
\end{align}
where (i) introduces a parameter $$ \alpha \geq 1 $$ which we will optimise
later, and (ii) follows by substituting $$ u = e^{\lambda v} $$.
To bound the second term, we use the triangle inequality
$$ | X - Y | \leq | X - m_x | + | Y - m_X | $$ in combination with
$$ X $$ and $$ Y $$ being i.i.d.
\begin{align}
  \P (| X - Y | < t)
  \geq
  \P ( | X - m\_X | < \tfrac{t}{2} )
  \P ( | Y - m\_X | < \tfrac{t}{2} )
  \, .
\end{align}
Taking complements and rearranging
\begin{align}
  \P (| X - Y | \geq t)
  \leq
  2 \P (|X - m\_X| \geq \tfrac{t}{2})
  -
  \P (|X - m\_X| \geq \tfrac{t}{2})^2
  \leq
  2 \P (|X - m\_X| \geq \tfrac{t}{2})
  \, .
\end{align}
This inequality can thus be applied to our previous integral to obtain
\begin{align}
  \lambda
  \int\_{\frac{\log \alpha}{\lambda}}^\infty
    e^{\lambda v}
    \P (|X - Y| \geq \sqrt{v})
    \, \sd v
  &\leq
  2 \lambda
  \int\_{\frac{\log \alpha}{\lambda}}^\infty
    e^{\lambda v}
    \P (|X - m_x| \geq \tfrac{\sqrt{v}}{2})
    \, \sd v
  \newline
  &\overset{\text{(i)}}{\leq}
  2 \lambda c\_3
  \int\_{\frac{\log \alpha}{\lambda}}^\infty
    e^{(\lambda - \frac{c\_4}{4}) v}
    \, \sd v
  \newline
  &=
  2 \lambda c\_3
  \biggl[
    \frac{e^{(\lambda - \frac{c\_4}{4}) v}}{\lambda - \frac{c\_4}{4}}
  \biggr]\_{\frac{\log \alpha}{\lambda}}^\infty
  \overset{\text{(ii)}}{=}
  \frac{8 \lambda c\_3}{c\_4 - 4\lambda}
  \alpha^{-\left(\frac{c\_4}{4 \lambda} - 1 \right)}
\end{align}
where (i) is by substitution of the assumed concentration bound around the
median, and (ii) holds whenever $$ \lambda < \frac{c_4}{4} $$.

Substituting into our bound for $$ \E [e^{\lambda (X - Y)^2}] $$
\begin{align}
   \E \bigl[e^{\lambda (X - Y)^2}\bigr]
   &\leq
   \alpha \left(
     1
     +
     c
     \alpha^{-p}
   \right)
   \, ,
\end{align}
where we defined $$ c = \frac{8 \lambda c_3}{c_4 - 4\lambda} $$ and
$$ p = \frac{c_4}{4 \lambda} $$.
We are now in position to optimise over $$ \alpha \geq 1 $$.
Taking the derivative, the unconstrained optimum is
$$ \alpha = [c (p - 1)]^{1 / p} = (2 c_3)^{1 / p} $$.
Since we do not have control over $$ c_3 $$ we introduce a new constant
$$ \tilde{c}_3 = c_3 \vee \frac{1}{2} $$ and observe that when $$ c_3 $$
entered the bound above, replacing it with $$ \tilde{c}_3 $$ would give
a further upper bound.
We can therefore replace $$ c $$ with
$$ \tilde{c} = \frac{8 \lambda \tilde{c}_3}{c_4 - 4\lambda} $$
and substitute $$ \alpha = (2 \tilde{c}_3)^{1 / p}$$ to obtain
\begin{align}
   \E \bigl[e^{\lambda (X - Y)^2}\bigr]
   &\leq
   [
     \tilde{c} (p - 1)
   ]^{1/p}
   +
   \tilde{c}
   =
   (2 \tilde{c}\_3)^{\frac{4 \lambda}{c_4}}
   +
   \frac{8 \lambda \tilde{c}_3}{c_4 - 4\lambda}
   \, .
\end{align}

The only remaining task is thus to optimise over $$ \lambda < \frac{c_4}{4} $$
\begin{align}
  \P (|X - \E [X]| \geq t)
  \leq
  e^{-\lambda t^2}
  \left[
    (2 \tilde{c}\_3)^{\frac{4 \lambda}{c_4}}
    +
    \frac{8 \lambda \tilde{c}_3}{c_4 - 4\lambda}
  \right]
  \, .
\end{align}
Making $$ \lambda $$ too small would yield the vacuous unit bound, while
approaching $$ \frac{c_4}{4} $$ from below makes the second term explode.
We thus somewhat arbitrarily take the midpoint $$ \lambda = \frac{c_4}{8} $$
which results in
\begin{align}
  \P (|X - \E [X]| \geq t)
  \leq
  c\_1
  e^{- c\_2 t^2 }
  \, ,
\end{align}
with $$ c_1 = \sqrt{2 \tilde{c}_3} (1 + \sqrt{2 \tilde{c}_3}) $$ and
$$ c_2 = \frac{c_4}{8} $$.

<span class="accent">
   The above bound is valid but **does not match the required constants!**
   While $$ c_3 $$ is usually larger than $$ 2 $$ and so its replacement
   with $$ \tilde{c}_3 = c_3 \vee \frac{1}{2} $$ would not be a problem,
   the constants in the book are better even if $$ \tilde{c}_3 $$ was replaced
   with the original $$ c_3 $$.
</span>




## Notes

- There is nothing special about the median in (d). In fact, we can obtain
a concentration bound for the mean similar to (d), whenever there exists
$$ a \in \R $$ such that $$ \P ( |X - a| \geq t ) \leq c_3 e^{-c_4 t^2} $$.
